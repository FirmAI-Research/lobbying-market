{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import sys\n",
    "import glob \n",
    "import json\n",
    "import importlib\n",
    "import tqdm\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nicoj\\Documents\\GitHub\\lobbying-market\n"
     ]
    }
   ],
   "source": [
    "#Make sure to run this only once, to make lobbying-market the working directory\n",
    "parent_dir_name=os.path.basename(os.path.dirname(os.getcwd()))\n",
    "if parent_dir_name=='lobbying-market':\n",
    "    os.chdir(os.path.pardir)\n",
    "    print(os.getcwd())\n",
    "    utils_path= os.path.abspath('utils')\n",
    "    sys.path.append(utils_path)\n",
    "\n",
    "import preprocessing as pp\n",
    "importlib.reload(pp)\n",
    "\n",
    "with open(\"LDA_data/issue_list.json\", 'r') as f:\n",
    "    issue_list = json.load(f)\n",
    "\n",
    "issue_df=pd.read_csv('LDA_data/data_by_issue.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_pattern='LDA_data/Filings_'\n",
    "dirdict={str(i):path_pattern + str(i) for i in range(2013,2024)}\n",
    "filepath_lists = {\n",
    "    yearkey:\n",
    "        [dirdict.get(yearkey)+'/'+filepath for filepath in os.listdir(dirdict.get(yearkey))] \n",
    "    for yearkey in dirdict\n",
    "}\n",
    "\n",
    "index_dict={\n",
    "    'Q'+str(i+1): [6*i+j for j in range(6)]+[2*i+j for j in range(24,26)] for i in range(4)\n",
    "}\n",
    "\n",
    "\n",
    "file_list_dependency={\n",
    "    yr_key : {\n",
    "       qt_key:\n",
    "           [filepath_lists[yr_key][i] for i in index_dict[qt_key]]\n",
    "    for qt_key in index_dict\n",
    "    }\n",
    "    for yr_key in filepath_lists\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: preprocessed_file_dict.keys()\n",
    "except: preprocessed_file_dict={}\n",
    "dir_path='LDA_data/processed'\n",
    "filelist= os.listdir(dir_path)\n",
    "for yr in range(2013,2024):\n",
    "    for j in range(4):\n",
    "        key=str(yr)+str(j+1)\n",
    "        i=(yr-2013)*4+j\n",
    "        preprocessed_file_dict[key]=dir_path+'/'+filelist[i]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df=pp.preprocess_data(pd.read_csv(file_list_dependency['2023']['Q4'][6]))\n",
    "#This saves the preprocessed data into csv files\n",
    "#It also saves the issue list\n",
    "os.makedirs('LDA_data/processed', exist_ok=True) \n",
    "warnings.filterwarnings('ignore')\n",
    "issue_set=set([])\n",
    "Year_Keys=list(file_list_dependency.keys())\n",
    "for yr_key in tqdm.tqdm(Year_Keys, desc = 'YEARS'):\n",
    "    #print(yr_key)\n",
    "    QT_Keys=list(file_list_dependency[yr_key].keys())\n",
    "    for qt_key in tqdm.tqdm(QT_Keys ,desc = 'Quarters'):\n",
    "        #print(qt_key)\n",
    "        df=pp.preprocess_data(pd.read_csv(file_list_dependency[yr_key][qt_key][6]))\n",
    "        filepath= 'LDA_data/processed/filings_'+yr_key+'_'+qt_key+'.csv'\n",
    "        df.to_csv(filepath,index=False)\n",
    "        issue_subset= set([col_name for col_name in df.columns if col_name.find('i_')>-1])\n",
    "        issue_set= issue_set.union(issue_subset)\n",
    "issue_list=list(issue_set)\n",
    "issue_set.remove('i_NUMBER')\n",
    "with open(\"LDA_data/issue_list.json\", 'w') as f:\n",
    "    json.dump(issue_list, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>issue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>i_ALC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i_AVI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i_HCR</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i_FIR</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i_UTI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i_GOV</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i_BAN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i_FUE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i_GAM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i_TAR</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79 rows × 0 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [i_ALC, i_AVI, i_HCR, i_FIR, i_UTI, i_EDU, i_ENV, i_AGR, i_CSP, i_LBR, i_CIV, i_ENG, i_URB, i_MON, i_RRR, i_CDT, i_LAW, i_FAM, i_ACC, i_VET, i_APP, i_POS, i_NAT, i_BUD, i_MED, i_SCI, i_CPI, i_INT, i_FIN, i_TOR, i_SMB, i_HOU, i_ANI, i_AUT, i_MAR, i_INS, i_DIS, i_FOO, i_RET, i_TRD, i_CON, i_CAW, i_MIA, i_MMM, i_CPT, i_RES, i_HOM, i_TRU, i_BEV, i_DOC, i_MAN, i_FOR, i_ROD, i_TOU, i_ECN, i_TEC, i_TRA, i_ART, i_CHM, i_WEL, i_TOB, i_WAS, i_BNK, i_PHA, i_ADV, i_IMM, i_COM, i_AER, i_SPO, i_REL, i_IND, i_TAX, i_UNM, i_DEF, i_GOV, i_BAN, i_FUE, i_GAM, i_TAR]\n",
       "\n",
       "[79 rows x 0 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_data_by_issue(df,qt_key):\n",
    "    df_to_load= pd.read_csv(preprocessed_file_dict[qt_key])\n",
    "    #print(df_to_load.shape)\n",
    "    for issue_key in df['issue']:\n",
    "        #print(issue_key)\n",
    "        #filter by issue==1\n",
    "        filtered_df= df_to_load[df_to_load[issue_key] == 1]\n",
    "        \n",
    "                \n",
    "        #count the rows in issue and add to dataframe\n",
    "        issue_count= filtered_df.shape[0]\n",
    "        col_name= 'count_'+qt_key\n",
    "        df.loc[issue_df['issue']==issue_key,col_name]=issue_count\n",
    "        #print(col_name+':'+str(issue_count))\n",
    "        \n",
    "        \n",
    "        #count the number of na in both income and expenses then add to dataframe\n",
    "        filter_na_income=filtered_df[filtered_df['income'].isna()]\n",
    "        filter_na_expenses=filter_na_income[filter_na_income['expenses'].isna()]\n",
    "        issue_count_na = filter_na_expenses.shape[0]\n",
    "        col_name= 'nan_'+qt_key\n",
    "        df.loc[issue_df['issue']==issue_key,col_name]=issue_count_na\n",
    "        #print(col_name+':'+str(issue_count_na))\n",
    "        \n",
    "        #sum income then add to dataframe\n",
    "        issue_income= sum(filtered_df['income'].dropna())\n",
    "        col_name= 'income_'+qt_key\n",
    "        df.loc[issue_df['issue']==issue_key,col_name]=issue_income\n",
    "        #print(col_name +':'+str(issue_income))\n",
    "        \n",
    "        #sum expenses then add to dataframe\n",
    "        issue_expenses= sum(filtered_df['expenses'].dropna())\n",
    "        col_name= 'expenses_'+qt_key\n",
    "        df.loc[issue_df['issue']==issue_key,col_name]=issue_expenses\n",
    "        #print(col_name+':'+str(issue_expenses))\n",
    "        \n",
    "        #sum total then add to dataframe\n",
    "        issue_total=issue_income+issue_expenses\n",
    "        col_name= 'total_'+qt_key\n",
    "        df.loc[issue_df['issue']==issue_key,col_name]=issue_total\n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [00:42<00:00,  1.03it/s]\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "issue_df= pd.DataFrame(issue_list,columns=['issue'])\n",
    "issue_df.set_index('issue')\n",
    "#add data to issue_df\n",
    "for qt_key in tqdf(preprocessed_file_dict):\n",
    "    add_data_by_issue(issue_df,qt_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "issue_df.to_csv('LDA_data/data_by_issue.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nicoenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
